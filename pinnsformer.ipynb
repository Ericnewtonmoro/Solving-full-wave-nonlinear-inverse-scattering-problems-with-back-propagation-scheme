{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "102uPfVY87faGq1sILP7dOV99go7a1wCi",
      "authorship_tag": "ABX9TyPthfN7n1PKQLsq4ce4wDze",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ericnewtonmoro/Solving-full-wave-nonlinear-inverse-scattering-problems-with-back-propagation-scheme/blob/master/pinnsformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "5VRpYtJBAXdn"
      },
      "outputs": [],
      "source": [
        "# implementation of PINNsformer\n",
        "# paper: PINNsFormer: A Transformer-Based Framework For Physics-Informed Neural Networks\n",
        "# link: https://arxiv.org/abs/2307.11833\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import pdb\n",
        "\n",
        "import sys\n",
        "import os\n",
        "\n",
        "def get_clones(module, N):\n",
        "    return nn.ModuleList([copy.deepcopy(module) for i in range(N)])\n",
        "\n",
        "class WaveAct(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(WaveAct, self).__init__()\n",
        "        self.w1 = nn.Parameter(torch.ones(1), requires_grad=True)\n",
        "        self.w2 = nn.Parameter(torch.ones(1), requires_grad=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.w1 * torch.sin(x)+ self.w2 * torch.cos(x)\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, d_model, d_ff=256):\n",
        "        super(FeedForward, self).__init__()\n",
        "        self.linear = nn.Sequential(*[\n",
        "            nn.Linear(d_model, d_ff),\n",
        "            WaveAct(),\n",
        "            nn.Linear(d_ff, d_ff),\n",
        "            WaveAct(),\n",
        "            nn.Linear(d_ff, d_model)\n",
        "        ])\n",
        "\n",
        "    def forward(self, x, y, t):\n",
        "        combined_input = torch.cat([x, y, t], dim=-1)\n",
        "        return self.linear(combined_input)\n",
        "\n",
        "\n",
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, heads):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "\n",
        "        self.attn = nn.MultiheadAttention(embed_dim=d_model, num_heads=heads, batch_first=True)\n",
        "        self.ff = FeedForward(d_model)\n",
        "        self.act1 = WaveAct()\n",
        "        self.act2 = WaveAct()\n",
        "\n",
        "    def forward(self, x, y, t):\n",
        "        x2 = self.act1(x)\n",
        "        # pdb.set_trace()\n",
        "        x = x + self.attn(x2,x2,x2)[0]\n",
        "        x2 = self.act2(x)\n",
        "        x = x + self.ff(x, y, t)\n",
        "        return x\n",
        "\n",
        "\n",
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, heads):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "\n",
        "        self.attn = nn.MultiheadAttention(embed_dim=d_model, num_heads=heads, batch_first=True)\n",
        "        self.ff = FeedForward(d_model)\n",
        "        self.act1 = WaveAct()\n",
        "        self.act2 = WaveAct()\n",
        "\n",
        "    def forward(self, x, y, t, e_outputs):\n",
        "        x2 = self.act1(x)\n",
        "        x = x + self.attn(x2, e_outputs, e_outputs)[0]\n",
        "        x2 = self.act2(x)\n",
        "        x = x + self.ff(x, y, t)\n",
        "        return x\n",
        "\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, d_model, N, heads):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.N = N\n",
        "        self.layers = get_clones(EncoderLayer(d_model, heads), N)\n",
        "        self.act = WaveAct()\n",
        "\n",
        "    def forward(self, x, y, t):\n",
        "        for i in range(self.N):\n",
        "            x = self.layers[i](x, y, t)\n",
        "        return self.act(x)\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, d_model, N, heads):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.N = N\n",
        "        self.layers = get_clones(DecoderLayer(d_model, heads), N)\n",
        "        self.act = WaveAct()\n",
        "\n",
        "    def forward(self, x, e_outputs):\n",
        "        for i in range(self.N):\n",
        "            x = self.layers[i](x, e_outputs)\n",
        "        return self.act(x)\n",
        "\n",
        "\n",
        "\n",
        "class PINNsformer(nn.Module):\n",
        "    def __init__(self, d_out=1, d_hidden=512, d_model=32, N=1, heads=2):\n",
        "        super(PINNsformer, self).__init__()\n",
        "\n",
        "        self.linear_emb = nn.Linear(2, d_model)\n",
        "\n",
        "        self.encoder = Encoder(d_model, N, heads)\n",
        "        self.decoder = Decoder(d_model, N, heads)\n",
        "        self.linear_out = nn.Sequential(*[\n",
        "            nn.Linear(d_model, d_hidden),\n",
        "            WaveAct(),\n",
        "            nn.Linear(d_hidden, d_hidden),\n",
        "            WaveAct(),\n",
        "            nn.Linear(d_hidden, d_out)\n",
        "        ])\n",
        "\n",
        "    def forward(self, x, y, t):\n",
        "        src = torch.cat((x,y,t), dim=-1)\n",
        "        src = self.linear_emb(src)\n",
        "\n",
        "        e_outputs = self.encoder(src)\n",
        "        d_output = self.decoder(src, e_outputs)\n",
        "        output = self.linear_out(d_output)\n",
        "        # pdb.set_trace()\n",
        "        # raise Exception('stop')\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rfK35wACY5_T"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}